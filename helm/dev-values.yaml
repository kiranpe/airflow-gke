
executor: KubernetesExecutor

airflow:
  config:
    AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
    AIRFLOW__KUBERNETES__DAGS_VOLUME_MOUNT_POINT: /opt/airflow/dags
    AIRFLOW__KUBERNETES__NAMESPACE: airflow
    AIRFLOW__KUBERNETES__DELETE_WORKER_PODS: "True"
    AIRFLOW__LOGGING__REMOTE_LOGGING: "True"
    AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER: gs://dev-airflow-logs
    AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID: google_cloud_default

  extraContainers:
    - name: cloudsql-proxy
      image: gcr.io/cloudsql-docker/gce-proxy:1.33.7
      command:
        - "/cloud_sql_proxy"
        - "-instances=mlops-448320:us-east1:airflow-sql=tcp:5432"
        - "-ip_address_types=PRIVATE"
      securityContext:
        runAsNonRoot: true
        runAsUser: 2

  extraEnv:
    - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
      valueFrom:
        secretKeyRef:
          name: airflow-db-secret
          key: connection

web:
  service:
    type: LoadBalancer
    annotations:
      cloud.google.com/load-balancer-type: "Internal"
    loadBalancerIP: 10.10.10.10
    ports:
      - port: 8080
        targetPort: 8080
        name: web

  extraLabels:
    component: web

dags:
  persistence:
    enabled: true
    existingClaim: airflow-dags-pvc

gcs:
  dags_bucket: dev-airflow-dags
  logs_bucket: dev-airflow-logs

triggerer:
  replicas: 1
  logs:
    persistence:
      enabled: true
      existingClaim: logs-airflow-triggerer
      storageClassName: gcsfuse-rwx   # âœ… or whatever SC you want
      accessMode: ReadWriteMany
      size: 5Gi

scheduler:
  replicas: 1

createUserJob:
  useHelmHooks: true
  applyCustomEnv: true
